{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGTuZ76MsCMsltdlH1XRJ+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oluwafemidiakhoa/MLprject/blob/main/AIReseacher.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4YY8XmV88Ua"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from openai import OpenAI, RateLimitError\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "from scipy.stats import linregress, ttest_ind\n",
        "\n",
        "# Set environment variables and initialize API clients\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "os.environ[\"KAGGLE_USERNAME\"] = os.getenv(\"KAGGLE_USERNAME\")\n",
        "os.environ[\"KAGGLE_KEY\"] = os.getenv(\"KAGGLE_KEY\")\n",
        "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Base class for agents with OpenAI and Kaggle functionalities\n",
        "class Agent:\n",
        "    def __init__(self, name, role):\n",
        "        self.name = name\n",
        "        self.role = role\n",
        "        self.api_client = client\n",
        "        self.kaggle_api = KaggleApi()\n",
        "        self.kaggle_api.authenticate()\n",
        "\n",
        "    def query_openai(self, prompt, retries=5, initial_delay=2):\n",
        "        for attempt in range(retries):\n",
        "            try:\n",
        "                response = self.api_client.chat.completions.create(\n",
        "                    model=\"gpt-4\",\n",
        "                    messages=[{\"role\": \"user\", \"content\": prompt}]\n",
        "                )\n",
        "                return response.choices[0].message.content\n",
        "            except RateLimitError:\n",
        "                if attempt < retries - 1:\n",
        "                    delay = initial_delay * (2 ** attempt)\n",
        "                    print(f\"Rate limit exceeded. Retrying in {delay} seconds...\")\n",
        "                    time.sleep(delay)\n",
        "                else:\n",
        "                    raise\n",
        "\n",
        "    def retrieve_kaggle_data(self, dataset, file_name):\n",
        "        print(\"\\n=== Downloading Dataset from Kaggle ===\")\n",
        "        self.kaggle_api.dataset_download_files(dataset, path=\".\", unzip=True)\n",
        "        print(f\"Downloaded and unzipped dataset: {dataset}.zip\")\n",
        "        return pd.read_csv(file_name)\n",
        "\n",
        "# Specialized agents for different research tasks\n",
        "class DataAnalysisAgent(Agent):\n",
        "    def plot_time_series(self, df):\n",
        "        df_yearly = df['AverageTemperature'].resample('Y').mean()\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(df_yearly.index, df_yearly, label=\"Yearly Avg Temp\")\n",
        "        plt.fill_between(df_yearly.index,\n",
        "                         df_yearly.rolling(window=5).mean() - 1.96 * df_yearly.rolling(window=5).std(),\n",
        "                         df_yearly.rolling(window=5).mean() + 1.96 * df_yearly.rolling(window=5).std(),\n",
        "                         alpha=0.2, label=\"95% Confidence Interval\")\n",
        "        plt.title(\"Yearly Global Average Temperature Trend with Confidence Interval\")\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"Temperature (°C)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def spectral_analysis(self, df):\n",
        "        temperature_data = df['AverageTemperature'].dropna()\n",
        "        temperature_fft = np.fft.fft(temperature_data)\n",
        "        freqs = np.fft.fftfreq(len(temperature_data))\n",
        "\n",
        "        plt.figure(figsize=(12, 6))\n",
        "        plt.plot(freqs[:len(freqs)//2], np.abs(temperature_fft[:len(freqs)//2]))\n",
        "        plt.title(\"Spectral Analysis of Temperature Anomalies\")\n",
        "        plt.xlabel(\"Frequency\")\n",
        "        plt.ylabel(\"Amplitude\")\n",
        "        plt.show()\n",
        "\n",
        "    def rolling_statistics(self, df):\n",
        "        df_yearly = df['AverageTemperature'].resample('Y').mean()\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(df_yearly.index, df_yearly, label=\"Yearly Avg Temp\")\n",
        "        plt.plot(df_yearly.index, df_yearly.rolling(window=5).mean(), label=\"5-Year Rolling Mean\", linestyle=\"--\")\n",
        "        plt.plot(df_yearly.index, df_yearly.rolling(window=20).mean(), label=\"20-Year Rolling Mean\", linestyle=\"--\")\n",
        "        plt.title(\"5-Year and 20-Year Rolling Mean of Global Temperature\")\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"Temperature (°C)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def compare_forecasting_models(self, df):\n",
        "        df_yearly = df['AverageTemperature'].resample('Y').mean().dropna()\n",
        "\n",
        "        arima_model = ARIMA(df_yearly, order=(5, 1, 0))\n",
        "        arima_fit = arima_model.fit()\n",
        "        arima_forecast = arima_fit.forecast(steps=20)\n",
        "\n",
        "        sarima_model = SARIMAX(df_yearly, order=(1, 1, 1), seasonal_order=(1, 1, 1, 12))\n",
        "        sarima_fit = sarima_model.fit()\n",
        "        sarima_forecast = sarima_fit.get_forecast(steps=20).predicted_mean\n",
        "\n",
        "        plt.figure(figsize=(14, 7))\n",
        "        plt.plot(df_yearly.index, df_yearly, label=\"Observed\")\n",
        "        plt.plot(pd.date_range(df_yearly.index[-1], periods=20, freq='Y'), arima_forecast, label=\"ARIMA Forecast\", linestyle=\"--\")\n",
        "        plt.plot(pd.date_range(df_yearly.index[-1], periods=20, freq='Y'), sarima_forecast, label=\"SARIMA Forecast\", linestyle=\"--\")\n",
        "        plt.title(\"ARIMA vs SARIMA Forecasting\")\n",
        "        plt.xlabel(\"Year\")\n",
        "        plt.ylabel(\"Temperature (°C)\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "    def hypothesis_testing(self, df):\n",
        "        df_yearly = df['AverageTemperature'].resample('Y').mean().dropna()\n",
        "        pre_1950 = df_yearly[df_yearly.index.year < 1950]\n",
        "        post_1950 = df_yearly[df_yearly.index.year >= 1950]\n",
        "\n",
        "        t_stat, p_value = ttest_ind(pre_1950, post_1950)\n",
        "        print(f\"T-Statistic: {t_stat}, P-Value: {p_value}\")\n",
        "        if p_value < 0.05:\n",
        "            print(\"Significant difference between pre-1950 and post-1950 average temperatures.\")\n",
        "        else:\n",
        "            print(\"No significant difference detected between pre-1950 and post-1950 temperatures.\")\n",
        "\n",
        "    def analyze_and_learn(self, df):\n",
        "        trend, intercept, r_value, p_value, std_err = linregress(df.index.year, df['AverageTemperature'])\n",
        "        summary = f\"Slope (°C/Year): {trend:.3f}\\nIntercept: {intercept:.3f}°C\\nR-squared: {r_value**2:.3f}\\nP-value: {p_value:.3e}\"\n",
        "        print(\"Trend Analysis:\\n\", summary)\n",
        "        return summary\n",
        "\n",
        "# Adding the remaining agents as specified, unchanged\n",
        "class LiteratureReviewAgent(Agent):\n",
        "    def conduct_review(self, topic):\n",
        "        prompt = f\"Conduct a literature review on {topic}, summarizing key findings, gaps, and challenges.\"\n",
        "        return self.query_openai(prompt)\n",
        "\n",
        "class HypothesisAgent(Agent):\n",
        "    def generate_hypotheses(self, literature):\n",
        "        prompt = f\"Generate hypotheses based on this literature review: {literature}\"\n",
        "        return self.query_openai(prompt)\n",
        "\n",
        "class ExperimentationAgent(Agent):\n",
        "    def design_experiment(self, hypothesis):\n",
        "        prompt = f\"Design an experiment to test this hypothesis: {hypothesis}\"\n",
        "        return self.query_openai(prompt)\n",
        "\n",
        "#class PredictiveModelAgent(Agent):\n",
        "    #def forecast_trends(self, df):\n",
        "        # Forecasting methods already handled within the DataAnalysisAgent\n",
        "\n",
        "class DocumentationAgent(Agent):\n",
        "    def compile_report(self, goal, literature, hypotheses, experiment, analysis_summary):\n",
        "        report = f\"\"\"\n",
        "        === Final Research Report ===\n",
        "\n",
        "        Goal:\n",
        "        {goal}\n",
        "\n",
        "        Literature Review:\n",
        "        {literature}\n",
        "\n",
        "        Hypotheses:\n",
        "        {hypotheses}\n",
        "\n",
        "        Experiment Design:\n",
        "        {experiment}\n",
        "\n",
        "        Data Analysis Summary:\n",
        "        {analysis_summary}\n",
        "        \"\"\"\n",
        "        print(report)\n",
        "        return report\n",
        "\n",
        "# Project Manager to coordinate tasks\n",
        "class ProjectManagerAgent(Agent):\n",
        "    def execute_research_workflow(self, goal, kaggle_dataset=None, file_name=None):\n",
        "        review_agent = LiteratureReviewAgent(\"Literature Review Agent\", \"Conducts literature reviews\")\n",
        "        hypothesis_agent = HypothesisAgent(\"Hypothesis Agent\", \"Generates hypotheses\")\n",
        "        experiment_agent = ExperimentationAgent(\"Experiment Agent\", \"Designs experiments\")\n",
        "        data_agent = DataRetrievalAgent(\"Data Agent\", \"Retrieves and preprocesses data\")\n",
        "        analysis_agent = DataAnalysisAgent(\"Data Analysis Agent\", \"Performs data analysis\")\n",
        "        model_agent = PredictiveModelAgent(\"Predictive Model Agent\", \"Forecasts trends\")\n",
        "        doc_agent = DocumentationAgent(\"Documentation Agent\", \"Compiles final report\")\n",
        "\n",
        "        print(\"\\n=== Starting Data Retrieval ===\")\n",
        "        data = data_agent.retrieve_and_preprocess_data(kaggle_dataset, file_name)\n",
        "\n",
        "        print(\"\\n=== Literature Review ===\")\n",
        "        literature_review = review_agent.conduct_review(goal)\n",
        "\n",
        "        print(\"\\n=== Hypothesis Generation ===\")\n",
        "        hypotheses = hypothesis_agent.generate_hypotheses(literature_review)\n",
        "\n",
        "        print(\"\\n=== Experiment Design ===\")\n",
        "        experiment_design = experiment_agent.design_experiment(hypotheses)\n",
        "\n",
        "        print(\"\\n=== Data Analysis ===\")\n",
        "        analysis_summary = analysis_agent.analyze_and_learn(data)\n",
        "        analysis_agent.plot_time_series(data)\n",
        "        analysis_agent.spectral_analysis(data)\n",
        "        analysis_agent.rolling_statistics(data)\n",
        "        analysis_agent.compare_forecasting_models(data)\n",
        "        analysis_agent.hypothesis_testing(data)\n",
        "\n",
        "        print(\"\\n=== Documentation ===\")\n",
        "        doc_agent.compile_report(goal, literature_review, hypotheses, experiment_design, analysis_summary)\n",
        "\n",
        "# Execution setup\n",
        "goal = \"Investigate the impact of climate change on global temperature trends using historical data.\"\n",
        "kaggle_dataset = \"berkeleyearth/climate-change-earth-surface-temperature-data\"\n",
        "file_name = \"GlobalLandTemperaturesByCity.csv\"\n",
        "\n",
        "manager = ProjectManagerAgent(\"Project Manager\", \"Orchestrates complex research workflows\")\n",
        "manager.execute_research_workflow(goal, kaggle_dataset, file_name)\n"
      ],
      "metadata": {
        "id": "-eA5ZcFU883W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Setting OpenAI API Key directly\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Replace with your actual API key\n",
        "\n",
        "# Set Kaggle credentials directly in the script\n",
        "# (ensure you have a Kaggle account and have generated an API token - kaggle.json)\n",
        "os.environ[\"KAGGLE_USERNAME\"] = \"\"  # Replace with your Kaggle username\n",
        "os.environ[\"KAGGLE_KEY\"] = \"\"  # Replace with your Kaggle API key\n",
        "\n",
        "\n",
        "# Check that the variables were set correctly\n",
        "print(\"Environment variables set for OpenAI and Kaggle.\")"
      ],
      "metadata": {
        "id": "AlP8xPlF9wtv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}